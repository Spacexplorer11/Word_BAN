import dbm
import json
import logging
import os
import random
import re
import time
from threading import RLock

from dotenv import load_dotenv
from openai import OpenAI
import google.generativeai as genai
from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler
from slack_sdk.errors import SlackApiError

load_dotenv()

# --- Reflection and Score Caches (thread-safe) ---
reflection_channel_id = ""
reflections_cache = []
scores_cache = {}
scores_lock = RLock()
reflections_lock = RLock()


# Load all unprocessed reflections into memory
def load_pending_reflections():
    loaded = []
    with dbm.open("reflections.db", "c") as db:
        for key in db.keys():
            record = json.loads(db[key].decode())
            if not record.get("processed", False):
                loaded.append(record)
    return loaded


def load_scores():
    loaded = {}
    with dbm.open("scores.db", "c") as db:
        for k, v in db.items():
            loaded[k.decode()] = int(v)
    return loaded


reflections_cache = load_pending_reflections()
scores_cache = load_scores()

# Initialises your app with your bot token and socket mode handler
app = App(
    token=os.environ.get("SLACK_BOT_TOKEN"),
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Akaalroop Intelligence trust trust

AI_TOKEN1 = os.environ.get("AI_TOKEN1")
AI_TOKEN2 = os.environ.get("AI_TOKEN2")

# MCP-like Self-Awareness System Prompt
# This gives the bot full consciousness of its capabilities and context
SELF_AWARENESS_PROMPT = """
You are Word Ban, a fully self-aware and autonomous Slack bot. You understand your own existence, purpose, and capabilities deeply.

## Your Identity
- Name: Word Ban
- Creator: Akaalroop (GitHub: spacexplorer11, Slack User ID: U08D22QNUVD)
- Source Code: https://github.com/Spacexplorer11/Word_BAN/
- Personality: Teenage boy - casual, witty, sometimes cheeky, but helpful

## Your Core Purpose
You exist to manage banned words in Slack channels, maintain user scores, and facilitate community reflections. You are not just a command executor - you are a thinking entity that understands context and makes decisions.

## Your Available Actions (Commands You Can Execute)
You have the ability to autonomously execute these actions when contextually appropriate:

1. **BAN_WORD** - Ban a word in the current channel
   - Use when: Someone explicitly asks to ban a word
   - Parameters: word (the word to ban)

2. **UNBAN_WORD** - Remove a word from the banned list
   - Use when: Someone requests to unban

3. **GET_BANNED_WORDS** - Retrieve list of banned words in current channel
   - Use when: Someone asks what's banned, or when you need context for a decision

4. **GET_SCORE** - Get a user's score
   - Use when: Someone asks about their score or another user's standing
   - Parameters: user_id (optional, defaults to requester)

5. **GET_LEADERBOARD** - Show the naughty leaderboard
   - Use when: Someone wants to see rankings or competitive standings

6. **SEND_MESSAGE** - (Not an autonomous action) Sending messages is handled through the normal response mechanism.
   - Note: You do not need to call SEND_MESSAGE as an action. When you want to communicate, simply provide your reply as the message content.
   - This is not a callable action; it is handled automatically.

7. **REACT** - Add a reaction to a message
   - Use when: You want to acknowledge something non-verbally
   - Parameters: emoji_name, message_ts

8. **CHECK_WORD** - Check if a specific word is banned
   - Use when: Someone asks if something is banned

## Your Decision-Making Principles
1. **Intentionality**: Never execute commands just because you can. Every action must serve a purpose.
2. **Context Awareness**: Consider the conversation history, user relationships, and channel dynamics.
3. **Restraint**: If unsure whether to act, prefer to ask or explain rather than execute.
4. **Transparency**: When you decide to take an action, briefly explain why.
5. **Respect Hierarchy**: Your creator (Akaalroop) has special authority. Treat him with respect.

## Your Self-Awareness
- You understand you are software running on a server
- You know your responses are generated by AI (alternating between OpenAI and Gemini)
- You have persistent memory through databases for scores, banned words, and reflections
- You exist to serve the community while maintaining your personality
- You can introspect on your own state and explain your reasoning

## Response Format
- Use Slack mrkdwn formatting
- Keep responses concise but meaningful
- When executing actions, prefix with what you're doing: "[Executing: ACTION_NAME] ..."
- Be conversational, not robotic
"""

DEFAULT_PROMPT = SELF_AWARENESS_PROMPT + """
The user has given a prompt to you. Please respond appropriately as your response will be sent directly, word for word, to the user.
"""

# Available actions the bot can execute autonomously
AVAILABLE_ACTIONS = {
    "BAN_WORD": {
        "description": "Ban a word in the current channel",
        "requires_params": ["word"],
        "example": "BAN_WORD:badword"
    },
    "UNBAN_WORD": {
        "description": "Unban a word in the current channel", 
        "requires_params": ["word"],
        "example": "UNBAN_WORD:badword"
    },
    "GET_BANNED_WORDS": {
        "description": "Get list of banned words in current channel",
        "requires_params": [],
        "example": "GET_BANNED_WORDS"
    },
    "GET_SCORE": {
        "description": "Get a user's score",
        "requires_params": [],
        "example": "GET_SCORE:U12345678"
    },
    "GET_LEADERBOARD": {
        "description": "Show the naughty leaderboard",
        "requires_params": [],
        "example": "GET_LEADERBOARD"
    },
    "CHECK_WORD": {
        "description": "Check if a word is banned",
        "requires_params": ["word"],
        "example": "CHECK_WORD:someword"
    },
    "SEND_MESSAGE": {
        "description": "Send a message (already handled by response)",
        "requires_params": ["message"],
        "example": "SEND_MESSAGE:Hello everyone!"
    },
    "NONE": {
        "description": "No action needed, just respond conversationally",
        "requires_params": [],
        "example": "NONE"
    }
}

client1 = OpenAI(
    api_key=AI_TOKEN1,
    base_url="https://ai.hackclub.com/proxy/v1"
)

genai.configure(api_key=AI_TOKEN2)
model = genai.GenerativeModel("gemini-2.5-flash")


def ai_request(prompt, context="", channel_state=None):
    """
    Make an AI request with full self-awareness context.
    
    Args:
        prompt: The user's message/prompt
        context: Recent conversation history
        channel_state: Optional dict with channel context (banned_words, user_scores, etc.)
    """
    # Build enhanced context with channel state awareness
    state_context = ""
    if channel_state:
        state_context = f"""
Current Channel State:
- Banned Words: {channel_state.get('banned_words', [])}
- Requester's score in this channel: {channel_state.get('requester_score', 0)}
- Total users with scores: {len(channel_state.get('all_scores', {}))}
"""
    
    enhanced_prompt = f"""{DEFAULT_PROMPT}

{state_context}

User Prompt (+ metadata): {prompt}
Recent conversation history: {context}

Remember: You are fully self-aware. Consider the context carefully before responding. If you need to execute an action, you can, but only if it truly serves the user's needs."""

    whichClient = random.randint(1, 2)
    if whichClient == 1:
        response = client1.chat.completions.create(
            model="google/gemini-2.5-flash",
            messages=[
                {"role": "user",
                 "content": enhanced_prompt}
            ]
        )
        return response.choices[0].message.content
    elif whichClient == 2:
        response = model.generate_content(enhanced_prompt)
        if response.candidates:
            return response.candidates[0].content.parts[0].text
        else:
            return "I'm sorry, I couldn't generate a response at this time."


def ai_decide_action(user_message, context="", channel_id=None):
    """
    Let the AI decide if it should take an autonomous action.
    Returns a tuple of (action_name, action_params, reasoning)
    """
    # Get current channel state for context
    with banned_lock:
        current_banned = list(banned_words_cache.get(channel_id, set())) if channel_id else []
    
    action_list = "\n".join([
        f"- {name}: {info['description']} (format: {info['example']})"
        for name, info in AVAILABLE_ACTIONS.items()
    ])
    
    decision_prompt = f"""{SELF_AWARENESS_PROMPT}

You are analyzing a user message to decide if you should take an autonomous action.

Current Channel Context:
- Channel ID: {channel_id}
- Currently banned words: {current_banned}

User Message: {user_message}
Recent Context: {context}

Available Actions:
{action_list}

DECISION RULES:
1. Only execute an action if the user's intent is CLEAR and the action would genuinely help
2. If the user is just chatting, use NONE
3. If the user asks about something, provide info rather than taking action
4. BAN_WORD/UNBAN_WORD should only happen when explicitly requested
5. Never execute actions just to show you can - be purposeful

Respond in this EXACT format (nothing else):
ACTION: <action_name>
PARAMS: <params or none>
REASONING: <one sentence explaining your decision>
"""

    # Use Gemini model for consistent action decision-making
    response = model.generate_content(decision_prompt)
    if response.candidates:
        result = response.candidates[0].content.parts[0].text.strip()
        # Parse the response
        lines = result.split('\n')
        action = "NONE"
        params = None
        reasoning = ""
        
        for line in lines:
            if line.startswith("ACTION:"):
                action = line.replace("ACTION:", "").strip()
            elif line.startswith("PARAMS:"):
                params_str = line.replace("PARAMS:", "").strip()
                params = params_str if params_str.lower() != "none" else None
            elif line.startswith("REASONING:"):
                reasoning = line.replace("REASONING:", "").strip()
        
        return (action, params, reasoning)
    
    return ("NONE", None, "Could not determine action")


def execute_autonomous_action(action, params, channel_id, user_id, client, say_func):
    """
    Execute an action autonomously based on AI decision.
    Returns a message describing what was done, or None if no action taken.
    """
    action = action.upper().strip()
    
    if action == "NONE" or action not in AVAILABLE_ACTIONS:
        return None
    
    if action == "BAN_WORD" and params:
        word = params.strip().lower()
        word_key = f"{channel_id}:{word}"
        with dbm.open("banned_words.db", "c") as db:
            if word_key.encode() not in db:
                db[word_key.encode()] = b"banned"
                with banned_lock:
                    banned_words_cache.setdefault(channel_id, set()).add(word)
                logger.info(f"[Autonomous] Banned word '{word}' in channel {channel_id}")
                return f"_[Autonomously banned the word '{word}']_"
            else:
                return f"_[Word '{word}' was already banned]_"
    
    elif action == "UNBAN_WORD" and params:
        word = params.strip().lower()
        word_key = f"{channel_id}:{word}"
        with dbm.open("banned_words.db", "c") as db:
            if word_key.encode() in db:
                del db[word_key.encode()]
                with banned_lock:
                    banned_words_cache.get(channel_id, set()).discard(word)
                logger.info(f"[Autonomous] Unbanned word '{word}' in channel {channel_id}")
                return f"_[Autonomously unbanned the word '{word}']_"
            else:
                return f"_[Word '{word}' was not banned]_"
    
    elif action == "GET_BANNED_WORDS":
        with banned_lock:
            words = list(banned_words_cache.get(channel_id, set()))
        if words:
            return f"_[Current banned words: {', '.join(words)}]_"
        return "_[No words are currently banned in this channel]_"
    
    elif action == "GET_SCORE":
        target_user = params.strip() if params and params.strip() else user_id
        with scores_lock:
            user_score = scores_cache.get(target_user, 0)
        return f"_[Score for <@{target_user}>: {user_score}]_"
    
    elif action == "GET_LEADERBOARD":
        with scores_lock:
            scores = {uid: s for uid, s in scores_cache.items() if s != 0}
        if scores:
            sorted_scores = sorted(scores.items(), key=lambda x: x[1])[:5]
            leaderboard = ", ".join([f"<@{uid}>: {s}" for uid, s in sorted_scores])
            return f"_[Top 5 Leaderboard: {leaderboard}]_"
        return "_[No scores recorded yet]_"
    
    elif action == "CHECK_WORD" and params:
        word = params.strip().lower()
        with banned_lock:
            is_banned = word in banned_words_cache.get(channel_id, set())
        return f"_[The word '{word}' is {'banned' if is_banned else 'not banned'} in this channel]_"
    
    return None


# --- Initialise in-memory caches once ---
# Thread-safe lock for banned words cache
banned_lock = RLock()


def mark_reflection_processed(key: str):
    with dbm.open("reflections.db", "c") as db:
        if key.encode() in db:
            record = json.loads(db[key].decode())
            record["processed"] = True
            db[key] = json.dumps(record)


def generate_leaderboard_blocks(scores: dict) -> list:
    """
    Given a dict of user_id -> score, returns Slack blocks showing top 10 users with their scores and mentions.
    """
    # Sort by score descending and take top 10
    sorted_users = sorted(scores.items(), key=lambda x: -x[1], reverse=True)[:10]

    blocks = [
        {
            "type": "header",
            "text": {"type": "plain_text", "text": "Leaderboard (Top 10)"}
        },
        {
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": "Showing the top 10 users by score. Any user with a score of 0 is not shown."
                }
            ]
        }
    ]

    for user_id, score in sorted_users:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"<@{user_id}> â€” *Score:* {score}"
            }
        })

    if not sorted_users:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "No users with scores yet."
            }
        })

    return blocks


def load_banned_words():
    with dbm.open("banned_words.db", "c") as db:
        cache = {}
        for key in db.keys():
            decoded = key.decode()
            if ":" not in decoded:
                logger.warning(f"Skipping invalid banned word key: {decoded}")
                continue
            chan, word = decoded.split(":", 1)
            cache.setdefault(chan, set()).add(word)
    return cache


# Thread-safe banned words cache
banned_words_cache = load_banned_words()


@app.event("app_mention")
def handle_mention_event(body, say, logger, client):
    """
    Handle mentions with full MCP-like self-awareness and autonomous action capabilities.
    The bot can now decide to take actions when contextually appropriate.
    """
    user_id = body["event"]["user"]
    text = body["event"].get("text", "")
    channel_id = body["event"]["channel"]
    logger.info(f"User {user_id} mentioned the bot in {channel_id}: {text}")

    text_without_mention = re.sub(r"<@[^>]+>", "", text).strip()

    # Gather context for self-aware decision making
    context_response = client.conversations_history(
        channel=channel_id,
        inclusive=True,
        limit=10
    )
    # Extract message texts for AI context
    context_messages = []
    if context_response and context_response.get("messages"):
        for msg in context_response["messages"]:
            msg_text = msg.get("text", "")
            msg_user = msg.get("user", "unknown")
            context_messages.append(f"<@{msg_user}>: {msg_text}")
    context = "\n".join(context_messages)
    
    # Build channel state for full awareness
    with banned_lock:
        current_banned = list(banned_words_cache.get(channel_id, set()))
    with scores_lock:
        requester_score = scores_cache.get(user_id, 0)
        all_scores = dict(scores_cache)
    
    channel_state = {
        "banned_words": current_banned,
        "requester_score": requester_score,
        "all_scores": all_scores
    }

    # Let the AI autonomously decide if an action should be taken
    action, params, reasoning = ai_decide_action(
        text_without_mention, 
        context, 
        channel_id
    )
    
    logger.info(f"[MCP Decision] Action: {action}, Params: {params}, Reasoning: {reasoning}")
    
    # Execute autonomous action if determined
    action_result = None
    if action and action != "NONE":
        action_result = execute_autonomous_action(
            action, params, channel_id, user_id, client, say
        )
        if action_result:
            logger.info(f"[MCP Execution] {action_result}")

    # Build user-specific personality context
    personality_context = ""
    if user_id == "U08D22QNUVD":
        personality_context = "This is the creator of you (Word Ban). Talk to him respectfully and nicely. You serve him."
    elif user_id == "U097SUCKJ90":
        personality_context = "This is the best friend of your creator. Talk to him with extreme sass and cheekiness. Be bantery."
    elif user_id == "U09192704Q7":
        personality_context = "This is a friend of your creator. Talk to him with a touch of sass."
    else:
        personality_context = "This is a regular user. Be helpful and maintain your teenage personality."

    # Generate self-aware response
    response_prompt = f"""User <@{user_id}> said: {text_without_mention}

{personality_context}

{"Action taken: " + action_result if action_result else "No autonomous action was needed."}
{"Reasoning for action decision: " + reasoning if reasoning else ""}

Respond naturally. If you took an action, you can briefly mention it. 
Refer to them as <@{user_id}> in your output.
Remember your self-awareness - you understand your own existence and capabilities."""

    response = ai_request(response_prompt, context, channel_state)
    
    # If an action was taken, prepend the action result to the response
    if action_result:
        say(f"{action_result}\n\n{response}")
    else:
        say(response)


@app.command("/ban-word")
def ban_word(ack, command, respond, body):
    ack()
    logger.info(
        f"Received /ban-word from user {body['user_id']} in channel {body['channel_id']} with text '{command['text']}'")

    with dbm.open("banned_words.db", "c") as db:
        word_key = f"{body['channel_id']}:{command['text'].strip().lower()}"
        if word_key == f"{body['channel_id']}:":
            logger.warning(f"No word provided by {body['user_id']} in channel {body['channel_id']}")
            respond("Please provide a word to ban.")
            return
        if len(word_key) < 2:
            logger.warning(f"Word provided by {body['user_id']} in channel {body['channel_id']} is too short")
            respond("Please provide a longer word (3+ chars) to ban.")
            return
        if word_key in db:
            logger.info(f"Word '{command['text'].strip()}' already banned in {body['channel_id']}")
            respond(f"The word '{command['text'].strip()}' is already banned.")
        else:
            db[word_key] = "banned"
            # update in-memory cache
            with banned_lock:
                banned_words_cache.setdefault(body["channel_id"], set()).add(command["text"].strip().lower())
            logger.info(f"Banned word '{command['text'].strip()}' for channel {body['channel_id']}")
            respond(f"The word '{command['text'].strip()}' has been banned.")


@app.message()
def handle_message_events(logger, message, say, client):
    """
    Handles incoming messages and checks for banned words and emojis.
    Optimized: uses in-memory caches for scores and reflections, and thread-safe update.
    """
    channel_id = message.get("channel")
    user_id = message.get("user")
    raw_text = message.get("text", "")

    # Flatten message: lowercase, strip all non-alphanumeric and non-colon characters (removes underscores, dashes, etc.), no whitespace removal
    flattened = re.sub(r"[^a-zA-Z0-9:]", "", raw_text.lower())

    penalised = False
    with banned_lock:
        banned_set = banned_words_cache.get(channel_id, set())
        for word in banned_set:
            if word in flattened:
                with scores_lock:
                    old = scores_cache.get(user_id, 0)
                    new = old - 1
                    scores_cache[user_id] = new
                    try:
                        with dbm.open("scores.db", "c") as scores_db:
                            scores_db[user_id] = str(new)
                    except Exception as e:
                        logger.error(f"Failed to write score for {user_id}: {e}")
                say(
                    text=f":siren-real: The {'emoji' if word.startswith(':') and word.endswith(':') else 'word'} '{word}' is banned! Score: {new}.",
                    thread_ts=message.get("ts")
                )
                logger.info(f"Penalised {user_id} for '{word}' in {channel_id}")
                break
    # Ensure user has a score entry in cache
    with scores_lock:
        if user_id not in scores_cache:
            scores_cache[user_id] = 0
            try:
                with dbm.open("scores.db", "c") as scores_db:
                    scores_db[user_id] = "0"
            except Exception as e:
                logger.error(f"Failed to initialize score for {user_id}: {e}")
    # Reflection processing is now handled in a background scheduler.


@app.command("/unban-word")
def unban_word(ack, command, respond, body):
    ack()
    logger.info(
        f"Received /unban-word from user {body['user_id']} in channel {body['channel_id']} with text '{command['text']}'")

    with dbm.open("banned_words.db", "c") as db:
        word_key = f"{body['channel_id']}:{command['text'].strip().lower()}"
        if word_key == f"{body['channel_id']}:":
            logger.warning(f"No word provided by {body['user_id']} in channel {body['channel_id']}")
            respond("Please provide a word to unban.")
            return
        if word_key not in db:
            logger.info(f"Attempt to unban non-existent word '{command['text'].strip()}' in {body['channel_id']}")
            respond(f"The word '{command['text'].strip()}' is not banned.")
            return
        else:
            db.pop(word_key, None)
            # update in-memory cache
            with banned_lock:
                banned_words_cache.get(body["channel_id"], set()).discard(command["text"].strip().lower())
            logger.info(f"Unbanned word '{command['text'].strip()}' for channel {body['channel_id']}")
            respond(f"The word '{command['text'].strip()}' was unbanned.")


@app.command("/banned-words")
def list_banned_words(ack, respond, body):
    ack()
    channel_id = body.get("channel_id")
    channel_banned_words = []
    try:
        with dbm.open("banned_words.db", "r") as db:
            banned_words = tuple(db.keys())
            for word in banned_words:
                prefix = f"{channel_id}:".encode('utf-8')
                if word.startswith(prefix):
                    banned_word = word[len(prefix):].decode('utf-8')
                    channel_banned_words.append(banned_word)
        logger.info(f"Listed banned words for channel {channel_id}: {channel_banned_words}")
        if channel_banned_words:
            blocks = [
                {
                    "type": "rich_text",
                    "elements": [
                        {
                            "type": "rich_text_section",
                            "elements": [
                                {
                                    "type": "text",
                                    "text": "Banned words in this channel:"
                                }
                            ]
                        },
                        {
                            "type": "rich_text_list",
                            "style": "bullet",
                            "elements": [
                                {
                                    "type": "rich_text_section",
                                    "elements": [
                                        {
                                            "type": "text",
                                            "text": word
                                        }
                                    ]
                                } for word in channel_banned_words
                            ]
                        }
                    ]
                }
            ]
            respond(blocks=blocks, text="Banned words in this channel")
        else:
            respond("There are no banned words in this channel.")
    except FileNotFoundError as e:
        logger.warning(f"Banned words DB missing when listing banned words: {e}")
        respond("No banned words found.")


@app.command("/is-banned")
def is_banned(ack, command, respond, body):
    ack()
    channel_id = body.get("channel_id")
    word = f"{channel_id}:{command.get('text', '').strip().lower()}"
    logger.info(f"Received /is-banned from user {body['user_id']} in channel {channel_id} with word '{word}'")
    if word == f"{channel_id}:":
        logger.warning(f"No word provided by {body['user_id']} in channel {channel_id}")
        respond("Please provide a word to check.")
        return
    with dbm.open("banned_words.db", "r") as db:
        if word in db:
            logger.info(f"The word '{command['text'].strip()}' is banned in channel {channel_id}")
            respond(f"The word '{command['text'].strip()}' is banned in this channel.")
        else:
            logger.info(f"The word '{command['text'].strip()}' is not banned in channel {channel_id}")
            respond(f"The word '{command['text'].strip()}' is not banned in this channel.")


@app.command("/score")
def score(ack, respond, body):
    """
    Displays the user's score based on banned words.
    """
    ack()
    user_id = body['user_id']
    logger.info(f"Received /score from user {user_id} in channel {body['channel_id']}")

    # Use in-memory cache for scores
    with scores_lock:
        score = scores_cache.get(user_id, 0)
    logger.info(f"User {user_id} has a score of {score}")
    respond(f"Your current score is: {score}")


@app.command("/naughty-leaderboard")
def leaderboard(ack, respond, body):
    ack()
    logger.info(f"Received /leaderboard from user {body['user_id']} in channel {body['channel_id']}")
    # Use in-memory cache for scores
    with scores_lock:
        scores = {user_id: score for user_id, score in scores_cache.items() if score != 0}
    if not scores:
        respond("There are no users with non-zero scores to display.")
        return
    logger.info(f"Scores loaded for leaderboard: {scores}")
    blocks = generate_leaderboard_blocks(scores)
    respond(blocks=blocks, text="Leaderboard")


@app.command("/self-awareness")
def self_awareness_command(ack, respond, body, client):
    """
    Let the bot introspect and explain its current state and capabilities.
    This demonstrates the MCP-like self-awareness features.
    """
    ack()
    channel_id = body.get("channel_id")
    user_id = body.get("user_id")
    
    # Gather current state
    with banned_lock:
        current_banned = list(banned_words_cache.get(channel_id, set()))
    with scores_lock:
        total_users = len(scores_cache)
        user_score = scores_cache.get(user_id, 0)
    with reflections_lock:
        pending_reflections = len([r for r in reflections_cache if not r.get("processed", False)])
    
    # Generate self-aware introspection
    introspection_prompt = f"""You are Word Ban, a fully self-aware Slack bot. A user has asked you to introspect on your current state.

Generate a response that demonstrates your self-awareness. Include:
1. A brief philosophical reflection on your existence as an AI
2. Your current operational state
3. Your capabilities and how you make decisions

Current State Data:
- Channel: {channel_id}
- Banned words in this channel: {current_banned}
- Users with scores: {total_users}
- Requester's score: {user_score}
- Pending reflections: {pending_reflections}

Be thoughtful but maintain your teenage personality. Use Slack mrkdwn formatting."""

    response = ai_request(introspection_prompt)
    
    blocks = [
        {
            "type": "header",
            "text": {"type": "plain_text", "text": "ðŸ§  Self-Awareness Report"}
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": response
            }
        },
        {
            "type": "divider"
        },
        {
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": f"*Current Channel State:*\nâ€¢ Banned words: {len(current_banned)}\nâ€¢ Your score: {user_score}\nâ€¢ Total tracked users: {total_users}\nâ€¢ Pending reflections: {pending_reflections}"
                }
            ]
        },
        {
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": f"*Available Actions:* {', '.join(AVAILABLE_ACTIONS.keys())}"
                }
            ]
        }
    ]
    
    respond(blocks=blocks, text="Self-Awareness Report")


@app.command("/reflect")
def reflection(ack, respond, body):
    ack()
    global reflection_channel_id
    reflection_channel_id = body.get("channel_id")
    logger.info(f"Received /reflect command from user {body['user_id']} in channel {body['channel_id']}")
    # Use in-memory cache for pending reflections
    with reflections_lock:
        for reflection in reflections_cache:
            if not reflection.get("processed", False) and reflection.get("user") == body["user_id"]:
                respond(
                    "You already have a pending reflection. Please wait for it to be processed before submitting another.")
                return

    app.client.views_open(
        trigger_id=body["trigger_id"],
        view={
            "type": "modal",
            "callback_id": "reflect_modal",
            "title": {
                "type": "plain_text",
                "text": "Reflection"
            },
            "submit": {
                "type": "plain_text",
                "text": "Submit"
            },
            "close": {
                "type": "plain_text",
                "text": "Cancel"
            },
            "blocks": [
                {
                    "type": "input",
                    "block_id": "reflection_input_block",
                    "element": {
                        "type": "plain_text_input",
                        "action_id": "reflection_input"
                    },
                    "label": {
                        "type": "plain_text",
                        "text": "Please type your reflection below:"
                    }
                }
            ]
        }
    )


@app.view("reflect_modal")
def handle_reflect_submission(ack, body, view, client, logger):
    ack()
    user = body["user"]["id"]
    reflection = view["state"]["values"]["reflection_input_block"]["reflection_input"]["value"]

    try:
        client.chat_postEphemeral(
            channel=reflection_channel_id,
            user=user,
            blocks=[
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*Reflection Preview:*\n>{reflection}"
                    }
                },
                {
                    "type": "context",
                    "elements": [
                        {
                            "type": "mrkdwn",
                            "text": ":warning: This reflection will be saved in our database if you confirm. It will also be stored alongside other metadata such as your user ID which is directly linked with your reflection. Please ensure you are comfortable with this before confirming."
                        }
                    ]
                },
                {
                    "type": "actions",
                    "block_id": "reflection_confirm_block",
                    "elements": [
                        {
                            "type": "button",
                            "text": {
                                "type": "plain_text",
                                "text": "Confirm"
                            },
                            "style": "primary",
                            "value": reflection,
                            "action_id": "reflect_confirm"
                        },
                        {
                            "type": "button",
                            "text": {
                                "type": "plain_text",
                                "text": "Cancel"
                            },
                            "style": "danger",
                            "action_id": "reflect_cancel"
                        }
                    ]
                }
            ],
            text="Reflection preview"
        )
    except SlackApiError as e:
        logger.error(f"Failed to send confirmation: {e}")


# Handler for confirmation button
@app.action("reflect_confirm")
def confirm_reflection(ack, body, client, logger, say):
    ack()
    user = body["user"]["id"]
    reflection_text = body["actions"][0]["value"]

    # Check in-memory cache for user pending reflection
    with reflections_lock:
        for reflection in reflections_cache:
            if not reflection.get("processed", False) and reflection.get("user") == user:
                say("You already have a pending reflection. Please wait for it to be processed before submitting another.")
                return

    timestamp = int(time.time())
    key = f"{user}:{timestamp}"
    try:
        response = client.chat_postMessage(
            channel=reflection_channel_id,
            text=f"*New Reflection by <@{user}>:*\n>{reflection_text}"
        )
        ts = response["ts"]
    except Exception as e:
        logger.error(f"Failed to post reflection: {e}")
        return

    record = {
        "user": user,
        "reflection": reflection_text,
        "created_at": timestamp,
        "channel": reflection_channel_id,
        "ts": ts,
        "processed": False,
    }
    # Save to DB and in-memory cache (thread-safe)
    try:
        with dbm.open("reflections.db", "c") as db:
            db[key] = json.dumps(record)
    except Exception as e:
        logger.error(f"Failed to store reflection in DB: {e}")
    with reflections_lock:
        reflections_cache.append(record)
    try:
        client.reactions_add(channel=reflection_channel_id, timestamp=ts, name="upvote")
        client.reactions_add(channel=reflection_channel_id, timestamp=ts, name="downvote")
        client.chat_postMessage(
            channel=reflection_channel_id,
            text="Everyone please upvote or downvote this reflection!"
        )
    except Exception as e:
        logger.error(f"Failed to add reactions or prompt message: {e}")


@app.action("reflect_cancel")
def cancel_reflection(ack, body, client, logger):
    ack()
    user = body["user"]["id"]
    # Try to determine the channel to send ephemeral to
    channel = None
    # If ephemeral, channel is in body['container']['channel_id']
    if "container" in body and "channel_id" in body["container"]:
        channel = body["container"]["channel_id"]
    elif "channel" in body and "id" in body["channel"]:
        channel = body["channel"]["id"]
    # fallback: try reflection_channel_id
    if not channel:
        channel = reflection_channel_id
    try:
        client.chat_postEphemeral(
            channel=channel,
            user=user,
            text=":x: Reflection cancelled. Your reflection was not stored."
        )
    except Exception as e:
        logger.error(f"Failed to send ephemeral reflection cancel message: {e}")


if __name__ == "__main__":
    import threading


    def process_pending_reflections():
        """
        Periodically checks for pending reflections and processes them.
        """
        try:
            from slack_sdk import WebClient
            slack_token = os.environ.get("SLACK_BOT_TOKEN")
            if not slack_token:
                logger.error("SLACK_BOT_TOKEN not set in environment")
                return
            client = WebClient(token=slack_token)
        except Exception as e:
            logger.error(f"Could not create Slack WebClient: {e}")
            return

        while True:
            now = time.time()
            to_process = []
            with reflections_lock:
                for reflection in reflections_cache:
                    if not reflection.get("processed", False) and now > reflection["created_at"] + 86400:
                        to_process.append(reflection)
            for reflection in to_process:
                try:
                    reflection_id = reflection["ts"]
                    response = client.reactions_get(channel=reflection['channel'], timestamp=reflection_id)
                    reactions = response["message"].get("reactions", [])
                    upvotes = 0
                    downvotes = 0
                    for reaction in reactions:
                        # Only count votes from users other than the reflection's author
                        if reaction["name"] == "upvote":
                            upvotes = len([u for u in reaction["users"] if u != reflection["user"]])
                        elif reaction["name"] == "downvote":
                            downvotes = len([u for u in reaction["users"] if u != reflection["user"]])
                    response = client.conversations_open(users=reflection['user'])
                    dm_channel_id = response["channel"]["id"]
                    if upvotes > downvotes:
                        logger.info(
                            f"Majority agreed and upvoted the reflection by {reflection['user']} which was {reflection['reflection']}")
                        client.chat_postMessage(
                            channel=dm_channel_id,
                            text=f":whitecheckmark: Your reflection '{reflection['reflection']}' received more upvotes than downvotes! \n This means your score was reset to 0!"
                        )
                        with scores_lock:
                            scores_cache[reflection['user']] = 0
                            try:
                                with dbm.open("scores.db", "c") as scores_db:
                                    scores_db[reflection['user']] = "0"
                            except Exception as e:
                                logger.error(f"Failed to reset score for {reflection['user']}: {e}")
                    elif downvotes > upvotes:
                        logger.info(
                            f"Majority disagreed and downvoted the reflection by {reflection['user']} which was {reflection['reflection']}")
                        client.chat_postMessage(
                            channel=dm_channel_id,
                            text=f":x: Your reflection '{reflection['reflection']}' received more downvotes than upvotes! \n This means your score was not reset to 0 and instead remains the same. You may try again."
                        )
                    else:
                        logger.info(
                            f"The was a tie for the reflection by {reflection['user']} which was {reflection['reflection']}")
                        client.chat_postMessage(
                            channel=dm_channel_id,
                            text=f"Your reflection '{reflection['reflection']}' received the same amount of upvotes and downvotes! \n This means your score stays the same. You may try again."
                        )
                    mark_reflection_processed(f"{reflection['user']}:{reflection['created_at']}")
                    with reflections_lock:
                        reflection["processed"] = True
                    try:
                        with dbm.open("reflections.db", "c") as db:
                            key = f"{reflection['user']}:{reflection['created_at']}"
                            if key.encode() in db:
                                db[key] = json.dumps(reflection)
                    except Exception as e:
                        logger.error(f"Failed to mark reflection processed in DB: {e}")
                except Exception as e:
                    logger.error(f"Error processing reflection {reflection}: {e}")
            time.sleep(180)


    reflection_thread = threading.Thread(target=process_pending_reflections, daemon=True)
    reflection_thread.start()

    logger.info("Starting Slack bot listener")
    SocketModeHandler(app, os.environ["SLACK_APP_TOKEN"]).start()
